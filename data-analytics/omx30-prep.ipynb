{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "df=pd.read_csv('../data/data.csv.gz', compression='gzip', sep=',')\n",
    "df['timestamp'] = pd.to_datetime(df['time_stamp'], format=\"%Y-%m-%d %H:%M:%S\").dt.tz_convert('CET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_delta = df['stock_id'] - df['stock_id'].shift()\n",
    "time_delta = (df['timestamp'] - df['timestamp'].shift()).fillna(10000).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_split_index=df.index[stock_delta!=0].tolist()\n",
    "stock_split_index.append(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_split_index=df.index[abs(time_delta)>36000].tolist()\n",
    "day_split_index.insert(0, 0)\n",
    "day_split_index.append(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stock_id_list = df['stock_id'].unique().tolist()\n",
    "i = 0\n",
    "for stock_index in stock_id_list:\n",
    "    print(\"index: {}, id:{}\".format(i, stock_index))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_stock_index = 0\n",
    "time_series_list = []\n",
    "time_series_all_list = []\n",
    "for i in range(len(day_split_index) - 1):\n",
    "    start_index = day_split_index[i]\n",
    "    end_index = day_split_index[i + 1]\n",
    "    day_time_series = df.iloc[start_index:end_index]\n",
    "    time_series_list.append(day_time_series)\n",
    "    if end_index == stock_split_index[current_stock_index + 1]:\n",
    "        print(\"finished stock: {}, got {} time series\".format(current_stock_index, len(time_series_list)))\n",
    "        time_series_all_list.append(time_series_list)\n",
    "        time_series_list = []\n",
    "        current_stock_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock_id in range(len(stock_id_list)):\n",
    "    diff = time_series_all_list[stock_id][0]['open'].diff()\n",
    "\n",
    "    min_ = diff[diff>=0.005].min()\n",
    "    open_ = time_series_all_list[stock_id][-1]['open'].mean()\n",
    "\n",
    "    print(\"stockid:{} min={}, cost={}\".format(stock_id, min_, min_/open_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a new list\n",
    "value_result_list = []\n",
    "for s_id in range(len(time_series_all_list)):\n",
    "    new_list = [None] * len(time_series_all_list[0])\n",
    "    value_result_list.append(new_list)\n",
    "    \n",
    "\n",
    "#for stock_id in range(len(time_series_all_list)):\n",
    "for stock_id in (5,):\n",
    "    print(\"handling stock_id: {}\".format(stock_id))\n",
    "    for day_id in range(len(time_series_all_list[stock_id])):\n",
    "        # :-1 is that we don't like the last record at 17:30 which is a aggregated number.\n",
    "        df = time_series_all_list[stock_id][day_id].copy()\n",
    "        # some data might miss, we must make a right join with full time series\n",
    "        # and do fillna.\n",
    "        df2 = df.set_index('timestamp')\n",
    "        ts = df2.index.min()\n",
    "        start_time_str = \"{}-{:02d}-{:02d} 8:54:00\".format(ts.year, ts.month, ts.day)\n",
    "        start_ts = pd.Timestamp(start_time_str, tz=ts.tz)\n",
    "        # periods=510 means from 9 to 17.29\n",
    "        dti = pd.date_range(start_ts , periods=516, freq='min').to_series(keep_tz=True).rename('time')\n",
    "        # remove from 17.25 - 17.28\n",
    "        #dti.drop(dti.tail(5).head(4).index, inplace=True)\n",
    "        df3 = df2.join(dti, how='right')\n",
    "        if day_id == 0: # the first day, we must set the value from 8.55-8.59 as same as 9.00\n",
    "            df3['last'].iloc[0] = df3['last'].iloc[6]\n",
    "        else:\n",
    "            df3['last'].iloc[0] = time_series_all_list[stock_id][day_id-1]['last'].iloc[-1]\n",
    "        \n",
    "        \n",
    "        df3['last'].interpolate(method='linear', inplace=True)\n",
    "        df3['volume'].iloc[:6] = df3['volume'].iloc[6] / 6\n",
    "        df3['volume'].iloc[6] = df3['volume'].iloc[6] / 6\n",
    "        df3['volume'].iloc[-5:] = df3['volume'].iloc[-1]/5\n",
    "        \n",
    "        #TODO: FIXED ME, no nan in volume!\n",
    "        \n",
    "        \n",
    "        df = df3.reset_index().rename({'index':'timestamp'}, axis=1)\n",
    "\n",
    "        \n",
    "        #df['timestamp'] = pd.to_datetime(df['time_stamp'], format=\"%Y-%m-%d %H:%M:%S\").dt.tz_convert('Europe/Stockholm')\n",
    "        df['ema_1'] = df['last']\n",
    "        df['ema_5'] = df['last'].ewm(span=5, adjust=False).mean()\n",
    "        df['ema_10'] = df['last'].ewm(span=10, adjust=False).mean()\n",
    "        df['ema_20'] = df['last'].ewm(span=20, adjust=False).mean()\n",
    "        df['diff_ema_1']=(df['ema_1'].diff()[1:]/df['ema_1']).fillna(0)\n",
    "        df['diff_ema_5']=(df['ema_5'].diff()[1:]/df['ema_5']).fillna(0)\n",
    "        df['diff_ema_10']=(df['ema_10'].diff()[1:]/df['ema_10']).fillna(0)\n",
    "        df['diff_ema_20']=(df['ema_20'].diff()[1:]/df['ema_20']).fillna(0)\n",
    "        \n",
    "        df['volume'] = df['volume'].abs().fillna(0)\n",
    "        # the first diff at 9:00 is the difference between today's open and yesterday's last.\n",
    "        df['value_ema_1_beta_99'] = 0\n",
    "        df['value_ema_5_beta_99'] = 0\n",
    "        df['value_ema_10_beta_99'] = 0\n",
    "        df['value_ema_20_beta_99'] = 0\n",
    "        df['value_ema_1_beta_98'] = 0\n",
    "        df['value_ema_5_beta_98'] = 0\n",
    "        df['value_ema_10_beta_98'] = 0\n",
    "        df['value_ema_20_beta_98'] = 0\n",
    "        for iter_id in range(20):\n",
    "            df['value_ema_1_beta_99'] = df['diff_ema_1'].shift(-1).fillna(0) + \\\n",
    "                0.99 * df['value_ema_1_beta_99'].shift(-1).fillna(0)\n",
    "            df['value_ema_1_beta_98'] = df['diff_ema_1'].shift(-1).fillna(0) + \\\n",
    "                0.98 * df['value_ema_1_beta_98'].shift(-1).fillna(0)\n",
    "            df['value_ema_5_beta_99'] = df['diff_ema_5'].shift(-1).fillna(0) + \\\n",
    "                0.99 * df['value_ema_5_beta_99'].shift(-1).fillna(0)\n",
    "            df['value_ema_5_beta_98'] = df['diff_ema_5'].shift(-1).fillna(0) + \\\n",
    "                0.98 * df['value_ema_5_beta_98'].shift(-1).fillna(0)\n",
    "            df['value_ema_10_beta_99'] = df['diff_ema_10'].shift(-1).fillna(0) + \\\n",
    "                0.99 * df['value_ema_10_beta_99'].shift(-1).fillna(0)\n",
    "            df['value_ema_10_beta_98'] = df['diff_ema_10'].shift(-1).fillna(0) + \\\n",
    "                0.98 * df['value_ema_10_beta_98'].shift(-1).fillna(0)\n",
    "            df['value_ema_20_beta_99'] = df['diff_ema_20'].shift(-1).fillna(0) + \\\n",
    "                0.99 * df['value_ema_20_beta_99'].shift(-1).fillna(0)\n",
    "            df['value_ema_20_beta_98'] = df['diff_ema_20'].shift(-1).fillna(0) + \\\n",
    "                0.98 * df['value_ema_20_beta_98'].shift(-1).fillna(0)\n",
    "        # drop the first row because diff is nan    \n",
    "        #df.drop(0, inplace=True)\n",
    "        value_result_list[stock_id][day_id] = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_result_list[5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv files\n",
    "column_wanted_in_order = ['timestamp', 'last', 'volume', \n",
    "                          'diff_ema_1', 'diff_ema_5', \n",
    "                          'diff_ema_10', 'diff_ema_20', \n",
    "                          'value_ema_1_beta_98', 'value_ema_1_beta_99',\n",
    "                          'value_ema_5_beta_98', 'value_ema_5_beta_99', \n",
    "                          'value_ema_10_beta_98', 'value_ema_10_beta_99', \n",
    "                          'value_ema_20_beta_98', 'value_ema_20_beta_99']\n",
    "\n",
    "def add_step_columns(df):\n",
    "    df['step_of_day'] = np.arange(0, len(df))\n",
    "    day_of_week = df['timestamp'].iloc[0].weekday()\n",
    "    df['step_of_week'] = len(df) * day_of_week + df['step_of_day']\n",
    "    return df\n",
    "\n",
    "csv_save_path = 'csv_files/'\n",
    "npy_save_path = 'npy_files/'\n",
    "#for s_id in range(len(value_result_list)):\n",
    "for s_id in (5,):\n",
    "    df_merged = value_result_list[s_id][0][column_wanted_in_order]\n",
    "    df_merged = add_step_columns(df_merged)\n",
    "    for day_id in range(1, len(value_result_list[s_id])):\n",
    "        df = value_result_list[s_id][day_id][column_wanted_in_order]\n",
    "        df = add_step_columns(df)\n",
    "        df_merged = df_merged.append(df)\n",
    "    \n",
    "    \n",
    "    for ema in (10, 20):\n",
    "        for beta in (99, 98):\n",
    "            print(\"Saving to files for stock id:{} ema:{} beta:{}\".format(s_id, ema, beta))\n",
    "            npy_filename = npy_save_path + \"ema{}_beta{}_{}.npy\".format(ema, beta, s_id)\n",
    "            groups = df_merged.set_index('timestamp').groupby(lambda x: x.date())\n",
    "            data_list = []\n",
    "            column_list = ['step_of_day',\n",
    "                       'step_of_week',\n",
    "                       'diff_ema_{}'.format(ema), \n",
    "                       'volume',\n",
    "                       'value_ema_{}_beta_{}'.format(ema, beta),\n",
    "                       'timestamp',\n",
    "                       'last']\n",
    "            \n",
    "            for index, df in groups:\n",
    "                np_data = df.reset_index().rename({'index':'timestamp'}, axis=1)[column_list].values\n",
    "                data_list.append(np_data)\n",
    "            np.save(npy_filename, np.array(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
